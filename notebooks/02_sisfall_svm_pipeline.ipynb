{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7343364,"sourceType":"datasetVersion","datasetId":4263904}],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import + C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n\nimport os, re\nfrom glob import glob\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:25:25.774910Z","iopub.execute_input":"2026-01-31T15:25:25.775228Z","iopub.status.idle":"2026-01-31T15:25:25.780575Z","shell.execute_reply.started":"2026-01-31T15:25:25.775201Z","shell.execute_reply":"2026-01-31T15:25:25.779290Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Ch·ªët Data_Root + l·∫•y danh s√°ch File\nDATA_ROOT = \"/kaggle/input/sis-fall-original-dataset/SisFall_dataset\"\n\nall_files = glob(DATA_ROOT + \"/SA*/*.txt\")\nprint(\"Total files:\", len(all_files))\nprint(\"Example file:\", all_files[0] if len(all_files) > 0 else \"No files\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:25:25.782256Z","iopub.execute_input":"2026-01-31T15:25:25.782674Z","iopub.status.idle":"2026-01-31T15:25:26.250448Z","shell.execute_reply.started":"2026-01-31T15:25:25.782648Z","shell.execute_reply":"2026-01-31T15:25:26.249199Z"}},"outputs":[{"name":"stdout","text":"Total files: 3537\nExample file: /kaggle/input/sis-fall-original-dataset/SisFall_dataset/SA01/D09_SA01_R02.txt\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# H√†m g√°n nh√£n (FALL/ADL) t·ª´ t√™n File\ndef label_from_filename(path):\n    name = os.path.basename(path).upper()\n    if re.match(r\"F\\d{2}_\", name):\n        return 1  # FALL\n    if re.match(r\"D\\d{2}_\", name):\n        return 0  # ADL\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:25:26.252120Z","iopub.execute_input":"2026-01-31T15:25:26.252553Z","iopub.status.idle":"2026-01-31T15:25:26.257672Z","shell.execute_reply.started":"2026-01-31T15:25:26.252526Z","shell.execute_reply":"2026-01-31T15:25:26.256670Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# H√†m ƒë·ªçc File SisFall\n_num_re = re.compile(r\"[-+]?\\d+(?:[.,]\\d+)?\")\n\ndef load_sisfall_file(path):\n    rows = []\n    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n\n            toks = _num_re.findall(line)\n            if len(toks) < 6:\n                continue\n\n            vals = [t.replace(\",\", \".\") for t in toks[:6]]\n            try:\n                rows.append([float(v) for v in vals])\n            except:\n                continue\n\n    if len(rows) == 0:\n        raise ValueError(\"No numeric rows parsed\")\n    return np.asarray(rows, dtype=np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:25:26.258949Z","iopub.execute_input":"2026-01-31T15:25:26.259227Z","iopub.status.idle":"2026-01-31T15:25:26.273063Z","shell.execute_reply.started":"2026-01-31T15:25:26.259204Z","shell.execute_reply":"2026-01-31T15:25:26.271940Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Load to√†n b·ªô File -> x_raw, y_raw + th·ªëng k√™\nX_raw, y_raw = [], []\nbad_files = []\n\nfor p in all_files:\n    y = label_from_filename(p)\n    if y is None:\n        continue\n    try:\n        x = load_sisfall_file(p)   # (T, 6)\n        X_raw.append(x)\n        y_raw.append(y)\n    except Exception as e:\n        bad_files.append((p, str(e)))\n\nprint(\"Loaded signals:\", len(X_raw))\nprint(\"Bad files:\", len(bad_files))\nprint(\"FALL count:\", int(np.sum(y_raw)))\nprint(\"ADL count:\", len(y_raw) - int(np.sum(y_raw)))\n\nif len(X_raw) > 0:\n    print(\"Sample shape:\", X_raw[0].shape)\nelse:\n    print(\"No samples loaded yet.\")\n\n# in t·ªëi ƒëa 5 file l·ªói (n·∫øu c√≥)\nfor p, err in bad_files[:5]:\n    print(\"BAD:\", p, \"|\", err)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:25:26.275285Z","iopub.execute_input":"2026-01-31T15:25:26.275979Z","iopub.status.idle":"2026-01-31T15:27:42.019954Z","shell.execute_reply.started":"2026-01-31T15:25:26.275929Z","shell.execute_reply":"2026-01-31T15:27:42.018772Z"}},"outputs":[{"name":"stdout","text":"Loaded signals: 3537\nBad files: 0\nFALL count: 1723\nADL count: 1814\nSample shape: (2400, 6)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Windowing (C·∫Øt c·ª≠a s·ªï)\ndef sliding_window(x, win_size, step):\n    T, C = x.shape\n    if T < win_size:\n        return np.empty((0, win_size, C), dtype=np.float32)\n\n    windows = []\n    for start in range(0, T - win_size + 1, step):\n        windows.append(x[start:start + win_size])\n\n    return np.stack(windows).astype(np.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:27:42.021560Z","iopub.execute_input":"2026-01-31T15:27:42.021937Z","iopub.status.idle":"2026-01-31T15:27:42.028126Z","shell.execute_reply.started":"2026-01-31T15:27:42.021908Z","shell.execute_reply":"2026-01-31T15:27:42.026756Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# T·∫°o dataset window: X_windows, Y_windows\nWIN = 400\nSTEP = 200\n\nX_windows = []\ny_windows = []\n\nfor x, y in zip(X_raw, y_raw):\n    W = sliding_window(x, WIN, STEP)\n    if len(W) == 0:\n        continue\n    X_windows.append(W)\n    y_windows.append(np.full((W.shape[0],), y, dtype=np.int32))\n\nX_windows = np.concatenate(X_windows, axis=0)\ny_windows = np.concatenate(y_windows, axis=0)\n\nprint(\"X_windows shape:\", X_windows.shape)\nprint(\"y_windows shape:\", y_windows.shape)\nprint(\"Positive rate:\", float(y_windows.mean()))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:27:42.029420Z","iopub.execute_input":"2026-01-31T15:27:42.029820Z","iopub.status.idle":"2026-01-31T15:27:42.972769Z","shell.execute_reply.started":"2026-01-31T15:27:42.029783Z","shell.execute_reply":"2026-01-31T15:27:42.971757Z"}},"outputs":[{"name":"stdout","text":"X_windows shape: (56233, 400, 6)\ny_windows shape: (56233,)\nPositive rate: 0.42496398911671085\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Tr√≠ch ƒë·∫∑c tr∆∞ng (Features) cho RandomForest\ndef features_from_window(w):\n    feats = np.concatenate([\n        w.mean(axis=0),\n        w.std(axis=0),\n        w.max(axis=0),\n        w.min(axis=0),\n    ]).astype(np.float32)\n    return feats\n\nX_feat = np.stack([features_from_window(w) for w in X_windows])\nprint(\"X_feat shape:\", X_feat.shape)  # (N, 24)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:27:42.974067Z","iopub.execute_input":"2026-01-31T15:27:42.974400Z","iopub.status.idle":"2026-01-31T15:27:50.413425Z","shell.execute_reply.started":"2026-01-31T15:27:42.974373Z","shell.execute_reply":"2026-01-31T15:27:50.412376Z"}},"outputs":[{"name":"stdout","text":"X_feat shape: (56233, 24)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Train/Test split + Train RandomForest + ƒê√°nh gi√°\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nX_tr, X_te, y_tr, y_te = train_test_split(\n    X_feat, y_windows,\n    test_size=0.2,\n    random_state=42,\n    stratify=y_windows\n)\n\nrf = RandomForestClassifier(\n    n_estimators=300,\n    random_state=42,\n    n_jobs=-1,\n    class_weight=\"balanced\"\n)\n\nrf.fit(X_tr, y_tr)\ny_pred = rf.predict(X_te)\n\nprint(classification_report(y_te, y_pred, digits=4))\nprint(\"Confusion matrix:\\n\", confusion_matrix(y_te, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:27:50.414693Z","iopub.execute_input":"2026-01-31T15:27:50.415083Z","iopub.status.idle":"2026-01-31T15:28:25.191250Z","shell.execute_reply.started":"2026-01-31T15:27:50.415028Z","shell.execute_reply":"2026-01-31T15:28:25.190002Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0     0.9056    0.9688    0.9361      6467\n           1     0.9533    0.8634    0.9061      4780\n\n    accuracy                         0.9240     11247\n   macro avg     0.9295    0.9161    0.9211     11247\nweighted avg     0.9259    0.9240    0.9234     11247\n\nConfusion matrix:\n [[6265  202]\n [ 653 4127]]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# L∆∞u Model\nimport joblib\n\njoblib.dump(rf, \"sisfall_random_forest.joblib\")\nprint(\"Saved: sisfall_random_forest.joblib\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:28:25.192778Z","iopub.execute_input":"2026-01-31T15:28:25.193328Z","iopub.status.idle":"2026-01-31T15:28:25.474043Z","shell.execute_reply.started":"2026-01-31T15:28:25.193298Z","shell.execute_reply":"2026-01-31T15:28:25.472928Z"}},"outputs":[{"name":"stdout","text":"Saved: sisfall_random_forest.joblib\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Feature n√¢ng cao\nimport numpy as np\n\ndef advanced_features(w):\n    # w: (WIN,6) -> ax ay az gx gy gz\n    a = w[:, :3]\n    g = w[:, 3:6]\n    amag = np.sqrt((a*a).sum(axis=1))  # (WIN,)\n    gmag = np.sqrt((g*g).sum(axis=1))\n\n    feats = []\n\n    # stats 6 k√™nh g·ªëc\n    feats += list(w.mean(axis=0))\n    feats += list(w.std(axis=0))\n    feats += list(w.max(axis=0))\n    feats += list(w.min(axis=0))\n\n    # stats magnitude\n    feats += [amag.mean(), amag.std(), amag.max(), amag.min()]\n    feats += [gmag.mean(), gmag.std(), gmag.max(), gmag.min()]\n\n    # energy (mean squared)\n    feats += [(w*w).mean()]\n    feats += [(amag*amag).mean()]\n    feats += [(gmag*gmag).mean()]\n\n    return np.array(feats, dtype=np.float32)\n\nX_feat2 = np.stack([advanced_features(w) for w in X_windows])\nprint(\"X_feat2 shape:\", X_feat2.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:28:25.476995Z","iopub.execute_input":"2026-01-31T15:28:25.477379Z","iopub.status.idle":"2026-01-31T15:28:44.369639Z","shell.execute_reply.started":"2026-01-31T15:28:25.477349Z","shell.execute_reply":"2026-01-31T15:28:44.368674Z"}},"outputs":[{"name":"stdout","text":"X_feat2 shape: (56233, 35)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Train l·∫°i RF tr√™n feature m·ªõi + th·ª≠ threshold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nX_tr, X_te, y_tr, y_te = train_test_split(\n    X_feat2, y_windows, test_size=0.2, random_state=42, stratify=y_windows\n)\n\nrf2 = RandomForestClassifier(\n    n_estimators=600,\n    random_state=42,\n    n_jobs=-1,\n    class_weight=\"balanced_subsample\",\n    max_depth=None\n)\n\nrf2.fit(X_tr, y_tr)\n\nproba = rf2.predict_proba(X_te)[:, 1]\n\nfor thr in [0.5, 0.45, 0.4, 0.35]:\n    y_pred = (proba >= thr).astype(int)\n    print(\"\\n==== threshold =\", thr, \"====\")\n    print(classification_report(y_te, y_pred, digits=4))\n    print(\"Confusion matrix:\\n\", confusion_matrix(y_te, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:28:44.370971Z","iopub.execute_input":"2026-01-31T15:28:44.371385Z","iopub.status.idle":"2026-01-31T15:30:13.869364Z","shell.execute_reply.started":"2026-01-31T15:28:44.371356Z","shell.execute_reply":"2026-01-31T15:30:13.868248Z"}},"outputs":[{"name":"stdout","text":"\n==== threshold = 0.5 ====\n              precision    recall  f1-score   support\n\n           0     0.9110    0.9702    0.9396      6467\n           1     0.9557    0.8718    0.9118      4780\n\n    accuracy                         0.9283     11247\n   macro avg     0.9334    0.9210    0.9257     11247\nweighted avg     0.9300    0.9283    0.9278     11247\n\nConfusion matrix:\n [[6274  193]\n [ 613 4167]]\n\n==== threshold = 0.45 ====\n              precision    recall  f1-score   support\n\n           0     0.9293    0.9592    0.9440      6467\n           1     0.9423    0.9013    0.9213      4780\n\n    accuracy                         0.9346     11247\n   macro avg     0.9358    0.9302    0.9326     11247\nweighted avg     0.9348    0.9346    0.9344     11247\n\nConfusion matrix:\n [[6203  264]\n [ 472 4308]]\n\n==== threshold = 0.4 ====\n              precision    recall  f1-score   support\n\n           0     0.9432    0.9417    0.9424      6467\n           1     0.9213    0.9232    0.9223      4780\n\n    accuracy                         0.9338     11247\n   macro avg     0.9322    0.9325    0.9323     11247\nweighted avg     0.9339    0.9338    0.9339     11247\n\nConfusion matrix:\n [[6090  377]\n [ 367 4413]]\n\n==== threshold = 0.35 ====\n              precision    recall  f1-score   support\n\n           0     0.9576    0.9184    0.9376      6467\n           1     0.8953    0.9450    0.9195      4780\n\n    accuracy                         0.9297     11247\n   macro avg     0.9265    0.9317    0.9285     11247\nweighted avg     0.9311    0.9297    0.9299     11247\n\nConfusion matrix:\n [[5939  528]\n [ 263 4517]]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import joblib\n\njoblib.dump(\n    {\n        \"model\": rf2,\n        \"threshold\": 0.4,\n        \"features\": \"advanced_features\",\n        \"win\": WIN,\n        \"step\": STEP\n    },\n    \"sisfall_rf_final.joblib\"\n)\n\nprint(\"Saved final model: sisfall_rf_final.joblib\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:30:13.870678Z","iopub.execute_input":"2026-01-31T15:30:13.871058Z","iopub.status.idle":"2026-01-31T15:30:14.436065Z","shell.execute_reply.started":"2026-01-31T15:30:13.871022Z","shell.execute_reply":"2026-01-31T15:30:14.435192Z"}},"outputs":[{"name":"stdout","text":"Saved final model: sisfall_rf_final.joblib\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## üîπ Support Vector Machine (SVM)","metadata":{}},{"cell_type":"code","source":"# Feature extraction\nimport numpy as np\n\ndef extract_features(window):\n    \"\"\"\n    window: (WIN, 6)\n    return: (30,) feature vector\n    \"\"\"\n    feats = []\n    for ch in range(window.shape[1]):\n        sig = window[:, ch]\n        feats.extend([\n            np.mean(sig),\n            np.std(sig),\n            np.max(sig),\n            np.min(sig),\n            np.mean(sig ** 2)  # energy\n        ])\n    return np.array(feats, dtype=np.float32)\n\n# Tr√≠ch feature cho to√†n b·ªô dataset\nX_svm = np.array([extract_features(w) for w in X_windows])\ny_svm = y_windows.copy()\n\nprint(\"X_svm shape:\", X_svm.shape)\nprint(\"y_svm shape:\", y_svm.shape)\nprint(\"Sample feature vector length:\", X_svm.shape[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:30:14.437098Z","iopub.execute_input":"2026-01-31T15:30:14.437376Z","iopub.status.idle":"2026-01-31T15:30:35.403042Z","shell.execute_reply.started":"2026-01-31T15:30:14.437350Z","shell.execute_reply":"2026-01-31T15:30:35.401996Z"}},"outputs":[{"name":"stdout","text":"X_svm shape: (56233, 30)\ny_svm shape: (56233,)\nSample feature vector length: 30\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Scale + split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Chia train / test\nX_train, X_test, y_train, y_test = train_test_split(\n    X_svm, y_svm,\n    test_size=0.2,\n    random_state=42,\n    stratify=y_svm\n)\n\n# Chu·∫©n h√≥a feature\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nprint(\"Train shape:\", X_train_scaled.shape)\nprint(\"Test shape :\", X_test_scaled.shape)\nprint(\"Mean (train, first feature):\", X_train_scaled[:, 0].mean())\nprint(\"Std  (train, first feature):\", X_train_scaled[:, 0].std())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:30:35.404344Z","iopub.execute_input":"2026-01-31T15:30:35.404748Z","iopub.status.idle":"2026-01-31T15:30:35.468299Z","shell.execute_reply.started":"2026-01-31T15:30:35.404687Z","shell.execute_reply":"2026-01-31T15:30:35.467255Z"}},"outputs":[{"name":"stdout","text":"Train shape: (44986, 30)\nTest shape : (11247, 30)\nMean (train, first feature): 0.0\nStd  (train, first feature): 1.0\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Train + Evaluate\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport time\n\n# ===== 1) SVM Linear (NHANH) =====\nt0 = time.time()\nsvm_linear = LinearSVC(\n    C=1.0,\n    class_weight=\"balanced\",\n    max_iter=20000,\n    random_state=42\n)\nsvm_linear.fit(X_train_scaled, y_train)\nt1 = time.time()\n\npred_linear = svm_linear.predict(X_test_scaled)\n\nprint(\"=== SVM Linear ===\")\nprint(f\"Train time: {t1 - t0:.2f}s\")\nprint(classification_report(y_test, pred_linear, digits=4))\nprint(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred_linear))\n\n# ===== 2) SVM RBF (M·∫†NH nh∆∞ng c√≥ th·ªÉ CH·∫¨M) =====\n# N·∫øu b·∫°n mu·ªën th·ª≠ lu√¥n, b·ªè comment 2 d√≤ng d∆∞·ªõi:\n# run_rbf = True\nrun_rbf = False\n\nif run_rbf:\n    t0 = time.time()\n    svm_rbf = SVC(\n        kernel=\"rbf\",\n        C=3.0,\n        gamma=\"scale\",\n        class_weight=\"balanced\"\n    )\n    svm_rbf.fit(X_train_scaled, y_train)\n    t1 = time.time()\n\n    pred_rbf = svm_rbf.predict(X_test_scaled)\n\n    print(\"\\n=== SVM RBF ===\")\n    print(f\"Train time: {t1 - t0:.2f}s\")\n    print(classification_report(y_test, pred_rbf, digits=4))\n    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred_rbf))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:30:35.469508Z","iopub.execute_input":"2026-01-31T15:30:35.470503Z","iopub.status.idle":"2026-01-31T15:30:36.272277Z","shell.execute_reply.started":"2026-01-31T15:30:35.470461Z","shell.execute_reply":"2026-01-31T15:30:36.271451Z"}},"outputs":[{"name":"stdout","text":"=== SVM Linear ===\nTrain time: 0.78s\n              precision    recall  f1-score   support\n\n           0     0.7835    0.8967    0.8363      6467\n           1     0.8263    0.6649    0.7368      4780\n\n    accuracy                         0.7982     11247\n   macro avg     0.8049    0.7808    0.7866     11247\nweighted avg     0.8017    0.7982    0.7940     11247\n\nConfusion matrix:\n [[5799  668]\n [1602 3178]]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":" # SVM Threshold Tuning \nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# L·∫•y decision score\nscores = svm_linear.decision_function(X_test_scaled)\n\nthresholds = [-1.0, -0.5, 0.0, 0.5, 1.0]\n\nfor th in thresholds:\n    y_pred_th = (scores > th).astype(int)\n    print(f\"\\n=== Threshold = {th} ===\")\n    print(classification_report(y_test, y_pred_th, digits=4))\n    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_th))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:30:36.273494Z","iopub.execute_input":"2026-01-31T15:30:36.273867Z","iopub.status.idle":"2026-01-31T15:30:36.335295Z","shell.execute_reply.started":"2026-01-31T15:30:36.273839Z","shell.execute_reply":"2026-01-31T15:30:36.334485Z"}},"outputs":[{"name":"stdout","text":"\n=== Threshold = -1.0 ===\n              precision    recall  f1-score   support\n\n           0     0.9379    0.0724    0.1344      6467\n           1     0.4418    0.9935    0.6117      4780\n\n    accuracy                         0.4639     11247\n   macro avg     0.6899    0.5329    0.3730     11247\nweighted avg     0.7271    0.4639    0.3372     11247\n\nConfusion matrix:\n [[ 468 5999]\n [  31 4749]]\n\n=== Threshold = -0.5 ===\n              precision    recall  f1-score   support\n\n           0     0.9312    0.3620    0.5213      6467\n           1     0.5275    0.9638    0.6819      4780\n\n    accuracy                         0.6178     11247\n   macro avg     0.7294    0.6629    0.6016     11247\nweighted avg     0.7596    0.6178    0.5896     11247\n\nConfusion matrix:\n [[2341 4126]\n [ 173 4607]]\n\n=== Threshold = 0.0 ===\n              precision    recall  f1-score   support\n\n           0     0.7835    0.8967    0.8363      6467\n           1     0.8263    0.6649    0.7368      4780\n\n    accuracy                         0.7982     11247\n   macro avg     0.8049    0.7808    0.7866     11247\nweighted avg     0.8017    0.7982    0.7940     11247\n\nConfusion matrix:\n [[5799  668]\n [1602 3178]]\n\n=== Threshold = 0.5 ===\n              precision    recall  f1-score   support\n\n           0     0.7592    0.9497    0.8439      6467\n           1     0.8971    0.5925    0.7136      4780\n\n    accuracy                         0.7979     11247\n   macro avg     0.8281    0.7711    0.7787     11247\nweighted avg     0.8178    0.7979    0.7885     11247\n\nConfusion matrix:\n [[6142  325]\n [1948 2832]]\n\n=== Threshold = 1.0 ===\n              precision    recall  f1-score   support\n\n           0     0.6129    0.9946    0.7584      6467\n           1     0.9535    0.1502    0.2595      4780\n\n    accuracy                         0.6357     11247\n   macro avg     0.7832    0.5724    0.5090     11247\nweighted avg     0.7577    0.6357    0.5464     11247\n\nConfusion matrix:\n [[6432   35]\n [4062  718]]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# SVM Save\nimport joblib\n\n# 1) Baseline config\njoblib.dump(\n    {\n        \"model\": svm_linear,\n        \"scaler\": scaler,\n        \"features\": \"statistical_30 (mean,std,max,min,energy) on 6 channels\",\n        \"threshold\": 0.0,\n        \"win\": WIN,\n        \"step\": STEP\n    },\n    \"svm_linear_baseline.joblib\"\n)\n\n# 2) High-recall config (∆∞u ti√™n b·∫Øt ng√£)\njoblib.dump(\n    {\n        \"model\": svm_linear,\n        \"scaler\": scaler,\n        \"features\": \"statistical_30 (mean,std,max,min,energy) on 6 channels\",\n        \"threshold\": -0.5,\n        \"win\": WIN,\n        \"step\": STEP\n    },\n    \"svm_linear_highrecall.joblib\"\n)\n\nprint(\"Saved:\")\nprint(\"- svm_linear_baseline.joblib\")\nprint(\"- svm_linear_highrecall.joblib\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T15:30:36.336529Z","iopub.execute_input":"2026-01-31T15:30:36.336943Z","iopub.status.idle":"2026-01-31T15:30:36.347077Z","shell.execute_reply.started":"2026-01-31T15:30:36.336916Z","shell.execute_reply":"2026-01-31T15:30:36.345912Z"}},"outputs":[{"name":"stdout","text":"Saved:\n- svm_linear_baseline.joblib\n- svm_linear_highrecall.joblib\n","output_type":"stream"}],"execution_count":19}]}